{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import time\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA = 0\n",
    "SEED = 600\n",
    "\n",
    "ESM_FILE = \"esm2_650m_out\"\n",
    "ESM_DIM = 1280\n",
    "ESM_LAYER = 33\n",
    "\n",
    "# ESM_FILE = \"esm2_3b_out\"\n",
    "# ESM_DIM = 2560\n",
    "# ESM_LAYER = 36\n",
    "\n",
    "LR = 0.001\n",
    "EPOCH = 50\n",
    "\n",
    "PROJ_PMHC_DIM_MI = 50\n",
    "PROJ_TCR_DIM_MI = 70\n",
    "FEAT_DIM = 70\n",
    "\n",
    "TEMPERATURE = 0.1\n",
    "\n",
    "K_NEG = 5\n",
    "\n",
    "BATCH_SIZE = (1+K_NEG)*50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.deterministic = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.fsencode(\"/project/DPDS/Wang_lab/shared/pMTnet_v2/data/ipd_imgt/\" + ESM_FILE)\n",
    "mhc_dic = {}\n",
    "for file in os.listdir(directory):\n",
    "    filename = os.fsdecode(file)\n",
    "    esm_file = torch.load(os.path.join(\"/project/DPDS/Wang_lab/shared/pMTnet_v2/data/ipd_imgt/\" + ESM_FILE, filename))\n",
    "    mhc_dic[filename.split(\".\")[0]] = esm_file[\"representations\"][ESM_LAYER]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa_dict_atchley=dict()\n",
    "aa_dict_dir='/work/DPDS/s213303/pmtnetv2/test_data/pmtnetv1/pMTnet-master/library/Atchley_factors.csv'\n",
    "with open(aa_dict_dir,'r') as aa:\n",
    "    aa_reader=csv.reader(aa)      \n",
    "    next(aa_reader, None)\n",
    "    for rows in aa_reader:\n",
    "        aa_name=rows[0]\n",
    "        aa_factor=rows[1:len(rows)]\n",
    "        aa_dict_atchley[aa_name]=np.asarray(aa_factor,dtype='float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def peptideMap(dataset, aa_dict, column, padding):\n",
    "    peptideArray = np.zeros((len(dataset), 1, padding, 5), dtype=np.float32)\n",
    "    for pos, seq in enumerate(dataset[column]):\n",
    "        peptideArray[pos, 0] = aamapping(seq, aa_dict, padding)\n",
    "    return peptideArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aamapping(peptideSeq, aa_dict, padding):\n",
    "    peptideArray = []\n",
    "    if len(peptideSeq)>padding:\n",
    "        #print('Length: '+str(len(peptideSeq))+'is over bound'+ ' (' +str(padding)+ ')' +'!')\n",
    "        peptideSeq=peptideSeq[0:padding]\n",
    "    for aa_single in peptideSeq:\n",
    "        try:\n",
    "            peptideArray.append(aa_dict[aa_single])\n",
    "        except:\n",
    "#            print('Inproper aa: ' + aa_single + ', in seq: ' + peptideSeq + '. 0 was applied for encoding.')\n",
    "            peptideArray.append(np.zeros(5, dtype='float32'))\n",
    "    return np.concatenate((np.asarray(peptideArray), np.zeros((padding - len(peptideSeq), 5), dtype='float32')), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mhcMap(dataset, allele, mhc_dic):\n",
    "    mhc_array = np.zeros((len(dataset), 1, 380, ESM_DIM), dtype=np.float32)\n",
    "    mhc_seen = dict()\n",
    "    for pos, mhc in enumerate(dataset[allele]):\n",
    "        try:\n",
    "            mhc_array[pos, 0] = mhc_seen[mhc]\n",
    "        except:\n",
    "            if len(mhc)>380:\n",
    "                print('Length: '+str(len(mhc))+'is over bound!')\n",
    "                mhc=mhc[0:380]\n",
    "            mhc_array[pos, 0] = esmmapping(mhc,mhc_dic)\n",
    "            mhc_seen[mhc] = mhc_array[pos, 0]\n",
    "    return mhc_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def esmmapping(mhc,mhc_dic):\n",
    "    mhc_encoding = mhc_dic[mhc].numpy()\n",
    "    num_padding = 380-mhc_encoding.shape[0]\n",
    "    return np.concatenate((mhc_encoding, np.zeros((num_padding,ESM_DIM),dtype='float32')), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(filedir, mhc_dic, a_allele, b_allele): \n",
    "    #1. input file path is valid or not\n",
    "    print('Processing: '+filedir)\n",
    "    if not os.path.exists(filedir):\n",
    "        print('Invalid file path: ' + filedir)\n",
    "        return 0\n",
    "    dataset = pd.read_csv(filedir, header=0, sep=\"\\t\")\n",
    "    print(\"Number of rows in raw dataset: \" + str(dataset.shape[0]))\n",
    "    dataset=dataset.dropna()\n",
    "    print(\"Number of rows in this dataset after dropping NA: \" + str(dataset.shape[0]))\n",
    "    #2. antigen peptide longer than 30 will be dropped\n",
    "    num_row = dataset.shape[0]\n",
    "    dataset_antigen_dropped = dataset[dataset.peptide.str.len()>30]\n",
    "    dataset=dataset[dataset.peptide.str.len()<=30]\n",
    "    if((num_row-dataset.shape[0])>0):\n",
    "        print(str(num_row-dataset.shape[0])+' antigens longer than ' + str(30) + 'aa are dropped:')\n",
    "        print(dataset_antigen_dropped)\n",
    "    #3. input MHC that is not in the ESM dictionary will be dropped\n",
    "    num_row = dataset.shape[0]\n",
    "    mhc_dic_keys = set(mhc_dic.keys())\n",
    "    dataset_mhc_alpha_dropped = dataset[~dataset[a_allele].isin(mhc_dic_keys)]\n",
    "    dataset_mhc_beta_dropped = dataset[~dataset[b_allele].isin(mhc_dic_keys)]\n",
    "    dataset = dataset[dataset[a_allele].isin(mhc_dic_keys)]\n",
    "    dataset = dataset[dataset[b_allele].isin(mhc_dic_keys)]\n",
    "    if((num_row-dataset.shape[0])>0):\n",
    "        print(str(num_row-dataset.shape[0])+' MHCs without ESM embedding are dropped:')\n",
    "        print(pd.unique(dataset_mhc_alpha_dropped[a_allele]))\n",
    "        print(pd.unique(dataset_mhc_beta_dropped[b_allele]))\n",
    "#    dataset = dataset.sample(frac=1)\n",
    "    dataset = dataset.reset_index(drop=True)\n",
    "    print(\"Number of rows in processed dataset: \" + str(dataset.shape[0]))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 1\n",
    "class pMHC(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(pMHC, self).__init__()\n",
    "        self.layerP1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 200,(2,5)),\n",
    "            nn.BatchNorm2d(200),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(200, 200,(2,1)),\n",
    "            nn.BatchNorm2d(200),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(200, 200,(2,1)),\n",
    "            nn.BatchNorm2d(200),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((30-3*2+3*1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(200, int(200/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(200/2), 3)\n",
    "        )\n",
    "        self.layerP2 = nn.Sequential(\n",
    "            nn.Conv2d(1, 200,(4,5)),\n",
    "            nn.BatchNorm2d(200),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(200, 200,(4,1)),\n",
    "            nn.BatchNorm2d(200),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(200, 200,(4,1)),\n",
    "            nn.BatchNorm2d(200),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((30-3*4+3*1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(200, int(200/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(200/2), 3)\n",
    "        )\n",
    "        self.layerP3 = nn.Sequential(\n",
    "            nn.Conv2d(1, 200,(6,5)),\n",
    "            nn.BatchNorm2d(200),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(200, 200,(6,1)),\n",
    "            nn.BatchNorm2d(200),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(200, 200,(6,1)),\n",
    "            nn.BatchNorm2d(200),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((30-3*6+3*1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(200, int(200/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(200/2), 3)\n",
    "        )\n",
    "        self.layerA1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 200,(10,ESM_DIM)),\n",
    "            nn.BatchNorm2d(200),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(200, 200,(10,1)),\n",
    "            nn.BatchNorm2d(200),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(200, 200,(10,1)),\n",
    "            nn.BatchNorm2d(200),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((380-3*10+3*1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(200, int(200/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(200/2), 3)\n",
    "        )\n",
    "        self.layerA2 = nn.Sequential(\n",
    "            nn.Conv2d(1, 200,(20,ESM_DIM)),\n",
    "            nn.BatchNorm2d(200),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(200, 200,(20,1)),\n",
    "            nn.BatchNorm2d(200),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(200, 200,(20,1)),\n",
    "            nn.BatchNorm2d(200),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((380-3*20+3*1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(200, int(200/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(200/2), 3)\n",
    "        )\n",
    "        self.layerA3 = nn.Sequential(\n",
    "            nn.Conv2d(1, 200,(30,ESM_DIM)),\n",
    "            nn.BatchNorm2d(200),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(200, 200,(30,1)),\n",
    "            nn.BatchNorm2d(200),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(200, 200,(30,1)),\n",
    "            nn.BatchNorm2d(200),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((380-3*30+3*1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(200, int(200/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(200/2), 3)\n",
    "        )\n",
    "        self.layerB1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 200,(10,ESM_DIM)),\n",
    "            nn.BatchNorm2d(200),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(200, 200,(10,1)),\n",
    "            nn.BatchNorm2d(200),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(200, 200,(10,1)),\n",
    "            nn.BatchNorm2d(200),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((380-3*10+3*1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(200, int(200/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(200/2), 3)\n",
    "        )\n",
    "        self.layerB2 = nn.Sequential(\n",
    "            nn.Conv2d(1, 200,(20,ESM_DIM)),\n",
    "            nn.BatchNorm2d(200),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(200, 200,(20,1)),\n",
    "            nn.BatchNorm2d(200),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(200, 200,(20,1)),\n",
    "            nn.BatchNorm2d(200),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((380-3*20+3*1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(200, int(200/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(200/2), 3)\n",
    "        )\n",
    "        self.layerB3 = nn.Sequential(\n",
    "            nn.Conv2d(1, 200,(30,ESM_DIM)),\n",
    "            nn.BatchNorm2d(200),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(200, 200,(30,1)),\n",
    "            nn.BatchNorm2d(200),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(200, 200,(30,1)),\n",
    "            nn.BatchNorm2d(200),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((380-3*30+3*1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(200, int(200/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(200/2), 3)\n",
    "        )\n",
    "        self.fc1 = nn.Linear(3 * 9, 30)\n",
    "        self.fc2 = nn.Linear(30, 3)\n",
    "    def forward(self, x_p, x_a, x_b):\n",
    "        f1_p = self.layerP1(x_p)\n",
    "        f2_p = self.layerP2(x_p)\n",
    "        f3_p = self.layerP3(x_p)\n",
    "        \n",
    "        f1_a = self.layerA1(x_a)\n",
    "        f2_a = self.layerA2(x_a)\n",
    "        f3_a = self.layerA3(x_a)\n",
    "        \n",
    "        f1_b = self.layerB1(x_b)\n",
    "        f2_b = self.layerB2(x_b)\n",
    "        f3_b = self.layerB3(x_b)\n",
    "        encoded = self.fc1(torch.cat((f1_p,f2_p,f3_p, f1_a,f2_a,f3_a, f1_b,f2_b,f3_b),dim=1))\n",
    "        encoded_act = F.relu(encoded)\n",
    "        return encoded_act, self.fc2(encoded_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. V gene alpha model\n",
    "class vGdVAEa(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(vGdVAEa, self).__init__()\n",
    "        self.layer1 = nn.Sequential(  \n",
    "            nn.Conv2d(1, 180,(10,5)),\n",
    "            nn.ReLU(),   \n",
    "            nn.MaxPool2d((100-10+1,1)),\n",
    "            nn.Flatten(), \n",
    "            nn.Linear(180, int(180/2)),    \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(180/2), 3)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(1, 180,(20,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((100-20+1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(180, int(180/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(180/2), 3)\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(1, 180,(30,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((100-30+1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(180, int(180/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(180/2), 3)\n",
    "        )\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(1, 180,(40,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((100-40+1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(180, int(180/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(180/2), 3)\n",
    "        )\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(1, 180,(50,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((100-50+1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(180, int(180/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(180/2), 3)\n",
    "        )\n",
    "        self.layer6 = nn.Sequential(\n",
    "            nn.Conv2d(1, 180,(60,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((100-60+1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(180, int(180/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(180/2), 3)\n",
    "        )\n",
    "        self.layer7 = nn.Sequential(\n",
    "            nn.Conv2d(1, 180,(70,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((100-70+1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(180, int(180/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(180/2), 3)\n",
    "        )\n",
    "        self.layer8 = nn.Sequential(\n",
    "            nn.Conv2d(1, 180,(80,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((100-80+1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(180, int(180/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(180/2), 3)\n",
    "        )\n",
    "        self.layer9 = nn.Sequential(\n",
    "            nn.Conv2d(1, 180,(90,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((100-90+1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(180, int(180/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(180/2), 3)\n",
    "        )\n",
    "        self.layer10 = nn.Sequential(\n",
    "            nn.Conv2d(1, 180,(100,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((100-100+1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(180, int(180/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(180/2), 3)\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(nn.TransformerEncoderLayer(d_model=5, nhead=5), num_layers=6)\n",
    "        self.linear1 = nn.Linear(in_features=3*10, out_features=int(3*10/2))\n",
    "        self.linear2 = nn.Linear(in_features=int(3*10/2), out_features=5)\n",
    "        self.linear3 = nn.Linear(in_features=int(3*10/2), out_features=5)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(in_features=5, out_features=int(180*10/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=int(180*10/2), out_features=180*10),\n",
    "            nn.Unflatten(1,(10,180,1)),\n",
    "            nn.Conv2d(in_channels=10, out_channels=1, kernel_size=(180-100+1,5), padding=(0,4))\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        padding_mask = torch.sum(x.squeeze(dim=1),dim=2) == 0\n",
    "        x = x.permute(2,1,0,3)\n",
    "        x = torch.squeeze(x,dim=1)\n",
    "        x = self.transformer_encoder(src = x,src_key_padding_mask = padding_mask)\n",
    "        x = torch.unsqueeze(x,dim=1)\n",
    "        x = x.permute(2,1,0,3)\n",
    "        f1 = self.layer1(x)\n",
    "        f2 = self.layer2(x)\n",
    "        f3 = self.layer3(x)\n",
    "        f4 = self.layer4(x)\n",
    "        f5 = self.layer5(x)\n",
    "        f6 = self.layer6(x)\n",
    "        f7 = self.layer7(x)\n",
    "        f8 = self.layer8(x)\n",
    "        f9 = self.layer9(x)\n",
    "        f10 = self.layer10(x)\n",
    "        h1 = F.relu(self.linear1(torch.cat((f1,f2,f3,f4,f5,f6,f7,f8,f9,f10),1)))\n",
    "        mu = self.linear2(h1)\n",
    "        logvar = self.linear3(h1)\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        encoded = mu + eps*std\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 v gene beta model\n",
    "class vGdVAEb(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(vGdVAEb, self).__init__()   \n",
    "        self.layer1 = nn.Sequential(  \n",
    "            nn.Conv2d(1, 180,(10,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((100-10+1,1)),\n",
    "            nn.Flatten(), \n",
    "            nn.Linear(180, int(180/2)),    \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(180/2), 3)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(1, 180,(20,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((100-20+1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(180, int(180/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(180/2), 3)\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(1, 180,(30,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((100-30+1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(180, int(180/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(180/2), 3)\n",
    "        )\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(1, 180,(40,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((100-40+1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(180, int(180/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(180/2), 3)\n",
    "        )\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(1, 180,(50,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((100-50+1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(180, int(180/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(180/2), 3)\n",
    "        )\n",
    "        self.layer6 = nn.Sequential(\n",
    "            nn.Conv2d(1, 180,(60,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((100-60+1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(180, int(180/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(180/2), 3)\n",
    "        )\n",
    "        self.layer7 = nn.Sequential(\n",
    "            nn.Conv2d(1, 180,(70,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((100-70+1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(180, int(180/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(180/2), 3)\n",
    "        )\n",
    "        self.layer8 = nn.Sequential(\n",
    "            nn.Conv2d(1, 180,(80,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((100-80+1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(180, int(180/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(180/2), 3)\n",
    "        )\n",
    "        self.layer9 = nn.Sequential(\n",
    "            nn.Conv2d(1, 180,(90,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((100-90+1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(180, int(180/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(180/2), 3)\n",
    "        )\n",
    "        self.layer10 = nn.Sequential(\n",
    "            nn.Conv2d(1, 180,(100,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((100-100+1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(180, int(180/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(180/2), 3)\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(nn.TransformerEncoderLayer(d_model=5, nhead=5), num_layers=6)\n",
    "        self.linear1 = nn.Linear(in_features=3*10, out_features=int(3*10/2))\n",
    "        self.linear2 = nn.Linear(in_features=int(3*10/2), out_features=5)\n",
    "        self.linear3 = nn.Linear(in_features=int(3*10/2), out_features=5)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(in_features=5, out_features=int(180*10/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=int(180*10/2), out_features=180*10),\n",
    "            nn.Unflatten(1,(10,180,1)),\n",
    "            nn.Conv2d(in_channels=10, out_channels=1, kernel_size=(180-100+1,5), padding=(0,4))\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        padding_mask = torch.sum(x.squeeze(dim=1),dim=2) == 0\n",
    "        x = x.permute(2,1,0,3)\n",
    "        x = torch.squeeze(x,dim=1)\n",
    "        x = self.transformer_encoder(src = x,src_key_padding_mask = padding_mask)\n",
    "        x = torch.unsqueeze(x,dim=1)\n",
    "        x = x.permute(2,1,0,3)\n",
    "        f1 = self.layer1(x)\n",
    "        f2 = self.layer2(x)\n",
    "        f3 = self.layer3(x)\n",
    "        f4 = self.layer4(x)\n",
    "        f5 = self.layer5(x)\n",
    "        f6 = self.layer6(x)\n",
    "        f7 = self.layer7(x)\n",
    "        f8 = self.layer8(x)\n",
    "        f9 = self.layer9(x)\n",
    "        f10 = self.layer10(x)\n",
    "        h1 = F.relu(self.linear1(torch.cat((f1,f2,f3,f4,f5,f6,f7,f8,f9,f10),1)))\n",
    "        mu = self.linear2(h1)\n",
    "        logvar = self.linear3(h1)\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        encoded = mu + eps*std\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 CDR3 alpha model\n",
    "class cdr3VAEa(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(cdr3VAEa, self).__init__()\n",
    "        self.layer1 = nn.Sequential(  \n",
    "            nn.Conv2d(1, 150,(1,5)),\n",
    "            nn.ReLU(),   \n",
    "            nn.MaxPool2d((25,1)),\n",
    "            nn.Flatten(), \n",
    "            nn.Linear(150, int(150/2)),    \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(150/2), 3)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(1, 150,(2,5)),\n",
    "            nn.ReLU(),\n",
    "            #nn.BatchNorm2d(30),\n",
    "            nn.MaxPool2d((25-2+1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(150, int(150/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(150/2), 3)\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(1, 150,(3,5)),\n",
    "            nn.ReLU(),\n",
    "            #nn.BatchNorm2d(30),\n",
    "            nn.MaxPool2d((25-3+1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(150, int(150/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(150/2), 3)\n",
    "        )\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(1, 150,(4,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((25-4+1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(150, int(150/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(150/2), 3)\n",
    "        )\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(1, 150,(5,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((25-5+1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(150, int(150/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(150/2), 3)\n",
    "        )\n",
    "        self.layer6 = nn.Sequential(\n",
    "            nn.Conv2d(1, 150,(6,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((25-6+1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(150, int(150/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(150/2), 3)\n",
    "        )\n",
    "        self.layer7 = nn.Sequential(\n",
    "            nn.Conv2d(1, 150,(7,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((25-7+1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(150, int(150/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(150/2), 3)\n",
    "        )\n",
    "        self.layer8 = nn.Sequential(\n",
    "            nn.Conv2d(1, 150,(8,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((25-8+1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(150, int(150/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(150/2), 3)\n",
    "        )\n",
    "        self.layer9 = nn.Sequential(\n",
    "            nn.Conv2d(1, 150,(9,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((25-9+1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(150, int(150/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(150/2), 3)\n",
    "        )\n",
    "        self.layer10 = nn.Sequential(\n",
    "            nn.Conv2d(1, 150,(10,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((25-10+1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(150, int(150/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(150/2), 3)\n",
    "        )\n",
    "        self.layer11 = nn.Sequential(\n",
    "            nn.Conv2d(1, 150,(11,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((25-11+1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(150, int(150/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(150/2), 3)\n",
    "        )\n",
    "        self.layer12 = nn.Sequential(\n",
    "            nn.Conv2d(1, 150,(12,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((25-12+1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(150, int(150/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(150/2), 3)\n",
    "        )\n",
    "        self.layer13 = nn.Sequential(\n",
    "            nn.Conv2d(1, 150,(13,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((25-13+1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(150, int(150/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(150/2), 3)\n",
    "        )\n",
    "        self.layer14 = nn.Sequential(\n",
    "            nn.Conv2d(1, 150,(14,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((25-14+1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(150, int(150/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(150/2), 3)\n",
    "        )\n",
    "        self.layer15 = nn.Sequential(\n",
    "            nn.Conv2d(1, 150,(15,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((25-15+1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(150, int(150/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(150/2), 3)\n",
    "        )\n",
    "        self.layer16 = nn.Sequential(\n",
    "            nn.Conv2d(1, 150,(16,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((25-16+1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(150, int(150/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(150/2), 3)\n",
    "        )\n",
    "        self.layer17 = nn.Sequential(\n",
    "            nn.Conv2d(1, 150,(17,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((25-17+1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(150, int(150/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(150/2), 3)\n",
    "        )\n",
    "        self.layer18 = nn.Sequential(\n",
    "            nn.Conv2d(1, 150,(18,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((25-18+1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(150, int(150/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(150/2), 3)\n",
    "        )\n",
    "        self.layer19 = nn.Sequential(\n",
    "            nn.Conv2d(1, 150,(19,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((25-19+1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(150, int(150/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(150/2), 3)\n",
    "        )\n",
    "        self.layer20 = nn.Sequential(\n",
    "            nn.Conv2d(1, 150,(20,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((25-20+1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(150, int(150/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(150/2), 3)\n",
    "        )\n",
    "        self.layer21 = nn.Sequential(\n",
    "            nn.Conv2d(1, 150,(21,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((25-21+1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(150, int(150/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(150/2), 3)\n",
    "        )\n",
    "        self.layer22 = nn.Sequential(\n",
    "            nn.Conv2d(1, 150,(22,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((25-22+1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(150, int(150/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(150/2), 3)\n",
    "        )\n",
    "        self.layer23 = nn.Sequential(\n",
    "            nn.Conv2d(1, 150,(23,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((25-23+1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(150, int(150/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(150/2), 3)\n",
    "        )\n",
    "        self.layer24 = nn.Sequential(\n",
    "            nn.Conv2d(1, 150,(24,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((25-24+1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(150, int(150/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(150/2), 3)\n",
    "        )\n",
    "        self.layer25 = nn.Sequential(\n",
    "            nn.Conv2d(1, 150,(25,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((25-25+1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(150, int(150/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(150/2), 3)\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(nn.TransformerEncoderLayer(d_model=5, nhead=5), num_layers=6)\n",
    "        self.linear1 = nn.Linear(in_features=3*25, out_features=30)\n",
    "        self.linear2 = nn.Linear(in_features=3*25, out_features=30)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(in_features=30, out_features=int(150*25/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=int(150*25/2), out_features=150*25),\n",
    "            nn.Unflatten(1,(25,150,1)),\n",
    "            nn.Conv2d(in_channels=25, out_channels=1, kernel_size=(150-25+1,5), padding=(0,4))\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        padding_mask = torch.sum(x.squeeze(dim=1),dim=2) == 0\n",
    "        x = x.permute(2,1,0,3)\n",
    "        x = torch.squeeze(x,dim=1)\n",
    "        x = self.transformer_encoder(src = x,src_key_padding_mask = padding_mask)\n",
    "        x = torch.unsqueeze(x,dim=1)\n",
    "        x = x.permute(2,1,0,3)\n",
    "        f1 = self.layer1(x)\n",
    "        f2 = self.layer2(x)\n",
    "        f3 = self.layer3(x)\n",
    "        f4 = self.layer4(x)\n",
    "        f5 = self.layer5(x)\n",
    "        f6 = self.layer6(x)\n",
    "        f7 = self.layer7(x)\n",
    "        f8 = self.layer8(x)\n",
    "        f9 = self.layer9(x)\n",
    "        f10 = self.layer10(x)\n",
    "        f11 = self.layer11(x)\n",
    "        f12 = self.layer12(x)\n",
    "        f13 = self.layer13(x)\n",
    "        f14 = self.layer14(x)\n",
    "        f15 = self.layer15(x)\n",
    "        f16 = self.layer16(x)\n",
    "        f17 = self.layer17(x)\n",
    "        f18 = self.layer18(x)\n",
    "        f19 = self.layer19(x)\n",
    "        f20 = self.layer20(x)\n",
    "        f21 = self.layer21(x)\n",
    "        f22 = self.layer22(x)\n",
    "        f23 = self.layer23(x)\n",
    "        f24 = self.layer24(x)\n",
    "        f25 = self.layer25(x)\n",
    "        mu = self.linear1(torch.cat((f1,f2,f3,f4,f5,f6,f7,f8,f9,f10,f11,f12,f13,f14,f15,f16,f17,f18,f19,f20,f21,f22,f23,f24,f25),1))\n",
    "        logvar = self.linear2(torch.cat((f1,f2,f3,f4,f5,f6,f7,f8,f9,f10,f11,f12,f13,f14,f15,f16,f17,f18,f19,f20,f21,f22,f23,f24,f25),1))\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        encoded = mu + eps*std\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 cdr3 beta\n",
    "class cdr3VAEb(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(cdr3VAEb, self).__init__()\n",
    "        self.layer1 = nn.Sequential(  \n",
    "            nn.Conv2d(1, 150,(1,5)),\n",
    "            nn.ReLU(),   \n",
    "            nn.MaxPool2d((25,1)),\n",
    "            nn.Flatten(), \n",
    "            nn.Linear(150, int(150/2)),    \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(150/2), 3)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(1, 150,(2,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((25-2+1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(150, int(150/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(150/2), 3)\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(1, 150,(3,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((25-3+1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(150, int(150/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(150/2), 3)\n",
    "        )\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(1, 150,(4,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((25-4+1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(150, int(150/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(150/2), 3)\n",
    "        )\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(1, 150,(5,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((25-5+1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(150, int(150/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(150/2), 3)\n",
    "        )\n",
    "        self.layer6 = nn.Sequential(\n",
    "            nn.Conv2d(1, 150,(6,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((25-6+1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(150, int(150/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(150/2), 3)\n",
    "        )\n",
    "        self.layer7 = nn.Sequential(\n",
    "            nn.Conv2d(1, 150,(7,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((25-7+1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(150, int(150/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(150/2), 3)\n",
    "        )\n",
    "        self.layer8 = nn.Sequential(\n",
    "            nn.Conv2d(1, 150,(8,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((25-8+1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(150, int(150/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(150/2), 3)\n",
    "        )\n",
    "        self.layer9 = nn.Sequential(\n",
    "            nn.Conv2d(1, 150,(9,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((25-9+1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(150, int(150/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(150/2), 3)\n",
    "        )\n",
    "        self.layer10 = nn.Sequential(\n",
    "            nn.Conv2d(1, 150,(10,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((25-10+1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(150, int(150/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(150/2), 3)\n",
    "        )\n",
    "        self.layer11 = nn.Sequential(\n",
    "            nn.Conv2d(1, 150,(11,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((25-11+1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(150, int(150/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(150/2), 3)\n",
    "        )\n",
    "        self.layer12 = nn.Sequential(\n",
    "            nn.Conv2d(1, 150,(12,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((25-12+1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(150, int(150/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(150/2), 3)\n",
    "        )\n",
    "        self.layer13 = nn.Sequential(\n",
    "            nn.Conv2d(1, 150,(13,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((25-13+1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(150, int(150/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(150/2), 3)\n",
    "        )\n",
    "        self.layer14 = nn.Sequential(\n",
    "            nn.Conv2d(1, 150,(14,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((25-14+1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(150, int(150/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(150/2), 3)\n",
    "        )\n",
    "        self.layer15 = nn.Sequential(\n",
    "            nn.Conv2d(1, 150,(15,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((25-15+1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(150, int(150/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(150/2), 3)\n",
    "        )\n",
    "        self.layer16 = nn.Sequential(\n",
    "            nn.Conv2d(1, 150,(16,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((25-16+1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(150, int(150/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(150/2), 3)\n",
    "        )\n",
    "        self.layer17 = nn.Sequential(\n",
    "            nn.Conv2d(1, 150,(17,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((25-17+1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(150, int(150/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(150/2), 3)\n",
    "        )\n",
    "        self.layer18 = nn.Sequential(\n",
    "            nn.Conv2d(1, 150,(18,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((25-18+1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(150, int(150/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(150/2), 3)\n",
    "        )\n",
    "        self.layer19 = nn.Sequential(\n",
    "            nn.Conv2d(1, 150,(19,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((25-19+1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(150, int(150/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(150/2), 3)\n",
    "        )\n",
    "        self.layer20 = nn.Sequential(\n",
    "            nn.Conv2d(1, 150,(20,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((25-20+1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(150, int(150/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(150/2), 3)\n",
    "        )\n",
    "        self.layer21 = nn.Sequential(\n",
    "            nn.Conv2d(1, 150,(21,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((25-21+1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(150, int(150/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(150/2), 3)\n",
    "        )\n",
    "        self.layer22 = nn.Sequential(\n",
    "            nn.Conv2d(1, 150,(22,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((25-22+1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(150, int(150/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(150/2), 3)\n",
    "        )\n",
    "        self.layer23 = nn.Sequential(\n",
    "            nn.Conv2d(1, 150,(23,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((25-23+1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(150, int(150/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(150/2), 3)\n",
    "        )\n",
    "        self.layer24 = nn.Sequential(\n",
    "            nn.Conv2d(1, 150,(24,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((25-24+1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(150, int(150/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(150/2), 3)\n",
    "        )\n",
    "        self.layer25 = nn.Sequential(\n",
    "            nn.Conv2d(1, 150,(25,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((25-25+1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(150, int(150/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(150/2), 3)\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(nn.TransformerEncoderLayer(d_model=5, nhead=5), num_layers=6)\n",
    "        self.linear1 = nn.Linear(in_features=3*25, out_features=30)\n",
    "        self.linear2 = nn.Linear(in_features=3*25, out_features=30)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(in_features=30, out_features=int(150*25/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=int(150*25/2), out_features=150*25),\n",
    "            nn.Unflatten(1,(25,150,1)),\n",
    "            nn.Conv2d(in_channels=25, out_channels=1, kernel_size=(150-25+1,5), padding=(0,4))\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        padding_mask = torch.sum(x.squeeze(dim=1),dim=2) == 0\n",
    "        x = x.permute(2,1,0,3)\n",
    "        x = torch.squeeze(x,dim=1)\n",
    "        x = self.transformer_encoder(src = x,src_key_padding_mask = padding_mask)\n",
    "        x = torch.unsqueeze(x,dim=1)\n",
    "        x = x.permute(2,1,0,3)\n",
    "        f1 = self.layer1(x)\n",
    "        f2 = self.layer2(x)\n",
    "        f3 = self.layer3(x)\n",
    "        f4 = self.layer4(x)\n",
    "        f5 = self.layer5(x)\n",
    "        f6 = self.layer6(x)\n",
    "        f7 = self.layer7(x)\n",
    "        f8 = self.layer8(x)\n",
    "        f9 = self.layer9(x)\n",
    "        f10 = self.layer10(x)\n",
    "        f11 = self.layer11(x)\n",
    "        f12 = self.layer12(x)\n",
    "        f13 = self.layer13(x)\n",
    "        f14 = self.layer14(x)\n",
    "        f15 = self.layer15(x)\n",
    "        f16 = self.layer16(x)\n",
    "        f17 = self.layer17(x)\n",
    "        f18 = self.layer18(x)\n",
    "        f19 = self.layer19(x)\n",
    "        f20 = self.layer20(x)\n",
    "        f21 = self.layer21(x)\n",
    "        f22 = self.layer22(x)\n",
    "        f23 = self.layer23(x)\n",
    "        f24 = self.layer24(x)\n",
    "        f25 = self.layer25(x)\n",
    "        mu = self.linear1(torch.cat((f1,f2,f3,f4,f5,f6,f7,f8,f9,f10,f11,f12,f13,f14,f15,f16,f17,f18,f19,f20,f21,f22,f23,f24,f25),1))\n",
    "        logvar = self.linear2(torch.cat((f1,f2,f3,f4,f5,f6,f7,f8,f9,f10,f11,f12,f13,f14,f15,f16,f17,f18,f19,f20,f21,f22,f23,f24,f25),1))\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        encoded = mu + eps*std\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_model(model_device):\n",
    "    \n",
    "    pMHCcheckpoint = torch.load(\"/work/DPDS/s213303/pmtnetv2/script/pytorch_model/pMHC_Copy42_Seed3000Channel200Batch200LR0.001Epoch20.pth\",map_location=model_device)\n",
    "    vGdVAEacheckpoint = torch.load(\"/work/DPDS/s213303/pmtnetv2/script/pytorch_model/vgene_dvae_Copy26_5neuron_Seed100Channel180Batch100LR0.0001Epoch390.pth\",map_location=model_device)\n",
    "    vGdVAEbcheckpoint = torch.load(\"/work/DPDS/s213303/pmtnetv2/script/pytorch_model/vgene_dvae_Copy29_5neuron_Seed100Channel180Batch100LR0.0001Epoch365.pth\",map_location=model_device)\n",
    "    cdr3VAEacheckpoint = torch.load(\"/work/DPDS/s213303/pmtnetv2/script/pytorch_model/cdr3_a_vae_Copy128_Seed100Bottle30Batch200Lr0.0005N_Trans6Channel150Embed3Epoch225.pth\",map_location=model_device)\n",
    "    cdr3VAEbcheckpoint = torch.load(\"/work/DPDS/s213303/pmtnetv2/script/pytorch_model/cdr3_b_vae_Copy132_Seed100Bottle30Batch200Lr0.0005N_Trans6Channel150Embed3Epoch170.pth\",map_location=model_device)\n",
    "    \n",
    "    CLmodel_new = pMHCTCR(temperature=TEMPERATURE).to(model_device)\n",
    "    \n",
    "    pMHCmodel_loaded = pMHC().to(model_device)\n",
    "    pMHCmodel_loaded.load_state_dict(pMHCcheckpoint['net'])\n",
    "\n",
    "    vGdVAEamodel_loaded = vGdVAEa().to(model_device)\n",
    "    vGdVAEamodel_loaded.load_state_dict(vGdVAEacheckpoint['net'])\n",
    "\n",
    "    vGdVAEbmodel_loaded = vGdVAEb().to(model_device)\n",
    "    vGdVAEbmodel_loaded.load_state_dict(vGdVAEbcheckpoint['net'])\n",
    "\n",
    "    cdr3VAEamodel_loaded = cdr3VAEa().to(model_device)\n",
    "    cdr3VAEamodel_loaded.load_state_dict(cdr3VAEacheckpoint['net'])\n",
    "\n",
    "    cdr3VAEbmodel_loaded = cdr3VAEb().to(model_device)\n",
    "    cdr3VAEbmodel_loaded.load_state_dict(cdr3VAEbcheckpoint['net'])\n",
    "    \n",
    "    return CLmodel_new, pMHCmodel_loaded, vGdVAEamodel_loaded, vGdVAEbmodel_loaded, cdr3VAEamodel_loaded, cdr3VAEbmodel_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pmhcEncoder(model, source_dataset, model_device):\n",
    "    x_p = torch.Tensor(peptideMap(source_dataset, aa_dict_atchley, \"peptide\", 30)).to(model_device)\n",
    "    x_a = torch.Tensor(mhcMap(source_dataset, \"mhca\", mhc_dic)).to(model_device)\n",
    "    x_b = torch.Tensor(mhcMap(source_dataset, \"mhcb\", mhc_dic)).to(model_device)\n",
    "    encoded, output = model(x_p, x_a, x_b)\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tcrEncoder(model, source_dataset, column, padding, model_device):\n",
    "    seq = torch.Tensor(peptideMap(source_dataset, aa_dict_atchley, column, padding)).to(model_device)\n",
    "    encoded, recon, mu, logvar = model(seq)\n",
    "    encoded[torch.isnan(encoded).all(dim=1)] = 0\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input dataset, like vcdr3pmhc\n",
    "# output Zpmhc * Ztcr\n",
    "class pMHCTCR(nn.Module):\n",
    "    def __init__(self, temperature):\n",
    "        super(pMHCTCR, self).__init__()\n",
    "        self.temperature = temperature\n",
    "        # Proj for pMHC\n",
    "        self.Proj1 = nn.Sequential(\n",
    "            nn.Linear(30, PROJ_PMHC_DIM_MI),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(PROJ_PMHC_DIM_MI, FEAT_DIM)\n",
    "        )\n",
    "        # Proj for TCR dim_in is 5*2+30*2\n",
    "        self.Proj2 = nn.Sequential(\n",
    "            nn.Linear(70, PROJ_TCR_DIM_MI),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(PROJ_TCR_DIM_MI, FEAT_DIM)\n",
    "        )\n",
    "    def forward(self, pmhc, tcr):\n",
    "        Zpmhc = F.normalize(self.Proj1(pmhc))\n",
    "        Ztcr = F.normalize(self.Proj2(tcr))\n",
    "        logits = torch.div(torch.diagonal(torch.mm(Zpmhc,Ztcr.T)),self.temperature)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it needs to be sure that there is at least 1 positive pair in the input data\n",
    "def LossFunction2(logits, label, pmhc_int, model_device):\n",
    "    # 1.1 matric for summing (all pairs)\n",
    "    label_pmhc_sum = torch.zeros(pmhc_int.max()+1, len(pmhc_int)).to(device)\n",
    "    label_pmhc_sum[pmhc_int, torch.arange(len(pmhc_int))] = 1\n",
    "    \n",
    "    # 1.2 sum\n",
    "    log_sum_exp_prob = torch.log(torch.matmul(label_pmhc_sum, torch.exp(logits)))\n",
    "\n",
    "    #----------------  --------------------------------------------------------\n",
    "    # 2.1 matrix for mean (only positive pairs)\n",
    "    label_pmhc_mean = F.normalize(label_pmhc_sum * label.repeat(pmhc_int.max()+1,1), p=1, dim=1)\n",
    "    \n",
    "    # 2.2 mean of positive\n",
    "    mean_pos_prob = torch.matmul(label_pmhc_mean, logits)\n",
    "    \n",
    "    loss = torch.sum(log_sum_exp_prob - mean_pos_prob)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, model, pmhcmodel, vamodel, vbmodel, cdr3amodel, cdr3bmodel, loss_fn, optimizer, model_device):\n",
    "    model.train()\n",
    "    pmhcmodel.train()\n",
    "    vamodel.train()\n",
    "    vbmodel.train()\n",
    "    cdr3amodel.train()\n",
    "    cdr3bmodel.train()\n",
    "    train_loss = 0.0\n",
    "    num_dataset = dataset.shape[0]\n",
    "    \n",
    "    for loop, batch in enumerate(range(0, num_dataset, BATCH_SIZE)):\n",
    "                \n",
    "        batch_data = dataset[batch:(batch+BATCH_SIZE)].reset_index(drop=True)\n",
    "                    \n",
    "        pmhc_batch_uniq = batch_data[[\"peptide\",\"mhca\",\"mhcb\",\"randn\"]].drop_duplicates()\n",
    "        pmhc_embedding = nn.functional.normalize(pmhcEncoder(pmhcmodel, pmhc_batch_uniq, model_device))\n",
    "        pmhc_embedding = pmhc_embedding.repeat_interleave(repeats=(1+K_NEG),dim=0)\n",
    "        \n",
    "        va_embedding = nn.functional.normalize(tcrEncoder(vamodel, batch_data, \"vaseq\", 100, model_device))\n",
    "        \n",
    "        vb_embedding = nn.functional.normalize(tcrEncoder(vbmodel, batch_data, \"vbseq\", 100, model_device))\n",
    "        \n",
    "        cdr3a_embedding = nn.functional.normalize(tcrEncoder(cdr3amodel, batch_data, \"cdr3a\", 25, model_device))\n",
    "        \n",
    "        cdr3b_embedding = nn.functional.normalize(tcrEncoder(cdr3bmodel, batch_data, \"cdr3b\", 25, model_device))\n",
    "        \n",
    "        tcr_embedding = torch.cat((va_embedding,vb_embedding,cdr3a_embedding,cdr3b_embedding),dim=1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        cos = model(pmhc_embedding, tcr_embedding)\n",
    "        \n",
    "        loss = loss_fn(cos,torch.from_numpy(batch_data['label'].values).to(model_device),torch.from_numpy(pd.Categorical(batch_data['randn']).codes.astype(\"int64\")),model_device)\n",
    "        \n",
    "        #loss.backward(retain_graph=True)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    return train_loss/(num_dataset/(1+K_NEG))\n",
    "\n",
    "    #return train_loss/((loop+1)*PMHC_PER_BATCH)\n",
    "    #return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val with AUROC\n",
    "# def val(dataset, model, pmhcmodel, vamodel, vbmodel, cdr3amodel, cdr3bmodel, model_device):\n",
    "#     model.eval()\n",
    "#     pmhcmodel.eval()\n",
    "#     vamodel.eval()\n",
    "#     vbmodel.eval()\n",
    "#     cdr3amodel.eval()\n",
    "#     cdr3bmodel.eval()\n",
    "#     results = []\n",
    "#     labels = []\n",
    "#     num_dataset = dataset.shape[0]\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         for loop, batch in enumerate(range(0, num_dataset, BATCH_SIZE)):\n",
    "#             batch_data = dataset[batch:(batch+BATCH_SIZE)].reset_index(drop=True)\n",
    "        \n",
    "#             #pmhc_data = batch_data[['mhca','mhcb','peptide']]\n",
    "#             pmhc_embedding = nn.functional.normalize(pmhcEncoder(pmhcmodel, batch_data, model_device))\n",
    "\n",
    "#             #va_data = batch_data[\"vaseq\"].to_frame(name=\"vaseq\")\n",
    "#             va_embedding = nn.functional.normalize(tcrEncoder(vamodel, batch_data, \"vaseq\", 100, model_device))\n",
    "\n",
    "#             #vb_data = batch_data[\"vbseq\"].to_frame(name=\"vbseq\")\n",
    "#             vb_embedding = nn.functional.normalize(tcrEncoder(vbmodel, batch_data, \"vbseq\", 100, model_device))\n",
    "\n",
    "#             #cdr3a_data = batch_data[\"cdr3a\"].to_frame(name=\"cdr3a\")\n",
    "#             cdr3a_embedding = nn.functional.normalize(tcrEncoder(cdr3amodel, batch_data, \"cdr3a\", 25, model_device))\n",
    "\n",
    "#             #cdr3b_data = batch_data[\"cdr3b\"].to_frame(name=\"cdr3b\")\n",
    "#             cdr3b_embedding = nn.functional.normalize(tcrEncoder(cdr3bmodel, batch_data, \"cdr3b\", 25, model_device))\n",
    "\n",
    "#             tcr_embedding = torch.cat((va_embedding,vb_embedding,cdr3a_embedding,cdr3b_embedding),dim=1)\n",
    "            \n",
    "#             cos = model(pmhc_embedding, tcr_embedding)\n",
    "            \n",
    "#             results.append(cos.detach().cpu().numpy())\n",
    "#             labels.append(batch_data['label'].values)\n",
    "    \n",
    "#     results_array = np.concatenate(results, axis=0)\n",
    "#     labels_array = np.concatenate(labels, axis=0)\n",
    "#     auroc = roc_auc_score(labels_array, results_array)\n",
    "#     return auroc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val with loss\n",
    "def val(dataset, model, pmhcmodel, vamodel, vbmodel, cdr3amodel, cdr3bmodel, loss_fn, model_device):\n",
    "    model.eval()\n",
    "    pmhcmodel.eval()\n",
    "    vamodel.eval()\n",
    "    vbmodel.eval()\n",
    "    cdr3amodel.eval()\n",
    "    cdr3bmodel.eval()\n",
    "    val_loss = 0.0\n",
    "    num_dataset = dataset.shape[0]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for loop, batch in enumerate(range(0, num_dataset, BATCH_SIZE)):\n",
    "            batch_data = dataset[batch:(batch+BATCH_SIZE)].reset_index(drop=True)\n",
    "        \n",
    "            pmhc_embedding = nn.functional.normalize(pmhcEncoder(pmhcmodel, batch_data, model_device))\n",
    "\n",
    "            va_embedding = nn.functional.normalize(tcrEncoder(vamodel, batch_data, \"vaseq\", 100, model_device))\n",
    "\n",
    "            vb_embedding = nn.functional.normalize(tcrEncoder(vbmodel, batch_data, \"vbseq\", 100, model_device))\n",
    "\n",
    "            cdr3a_embedding = nn.functional.normalize(tcrEncoder(cdr3amodel, batch_data, \"cdr3a\", 25, model_device))\n",
    "\n",
    "            cdr3b_embedding = nn.functional.normalize(tcrEncoder(cdr3bmodel, batch_data, \"cdr3b\", 25, model_device))\n",
    "\n",
    "            tcr_embedding = torch.cat((va_embedding,vb_embedding,cdr3a_embedding,cdr3b_embedding),dim=1)\n",
    "            \n",
    "            cos = model(pmhc_embedding, tcr_embedding)\n",
    "            \n",
    "            loss = loss_fn(cos,torch.from_numpy(batch_data['label'].values).to(model_device),torch.from_numpy(pd.Categorical(batch_data['valrandn']).codes.astype(\"int64\")),model_device)\n",
    "        \n",
    "            val_loss += loss.item()\n",
    "    \n",
    "    return val_loss/(num_dataset/(1+K_NEG))\n",
    "    #return val_loss/((loop+1)*PMHC_PER_BATCH)\n",
    "    #return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_script_num():\n",
    "    script_name_tmp1 = os.path.basename(__file__)\n",
    "    script_name_tmp2 = script_name_tmp1.split(\"-\")\n",
    "    script_name_tmp3 = script_name_tmp2[1].split(\".\")\n",
    "    script_num = script_name_tmp3[0]\n",
    "    return script_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(model_1, model_2):\n",
    "    models_differ = 0\n",
    "    for key_item_1, key_item_2 in zip(model_1.state_dict().items(), model_2.state_dict().items()):\n",
    "        if torch.equal(key_item_1[1], key_item_2[1]):\n",
    "            pass\n",
    "        else:\n",
    "            models_differ += 1\n",
    "            if (key_item_1[0] == key_item_2[0]):\n",
    "                pass\n",
    "                #print('Mismtach found at', key_item_1[0])\n",
    "            else:\n",
    "                raise Exception\n",
    "    if models_differ == 0:\n",
    "        print('Models match perfectly! :)')\n",
    "    else:\n",
    "        print(\"Models doesn't match\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: /project/DPDS/Wang_lab/shared/pMTnet_v2/data/vcdr3pmhc/pos1negk50/pairing_training_Dec19_all.txt\n",
      "Number of rows in raw dataset: 33149400\n",
      "Number of rows in this dataset after dropping NA: 33149400\n",
      "27000 MHCs without ESM embedding are dropped:\n",
      "['A*08:01' 'H-2-IAg7_alpha' 'A*02:15']\n",
      "['H-2-IAg7_beta']\n",
      "Number of rows in processed dataset: 33122400\n"
     ]
    }
   ],
   "source": [
    "# A*08:01 couldn't be found\n",
    "# A*02:15N\n",
    "# H-2-IAg7 couldn't be found\n",
    "training_dataset = preprocess(\"/project/DPDS/Wang_lab/shared/pMTnet_v2/data/vcdr3pmhc/pos1negk50/pairing_training_Dec19_all.txt\", mhc_dic, \"mhca\", \"mhcb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vb</th>\n",
       "      <th>va</th>\n",
       "      <th>peptide</th>\n",
       "      <th>mhca</th>\n",
       "      <th>mhcb</th>\n",
       "      <th>pMHC_SPECIES</th>\n",
       "      <th>TCR_SPECIES</th>\n",
       "      <th>class</th>\n",
       "      <th>randn</th>\n",
       "      <th>cdr3a</th>\n",
       "      <th>cdr3b</th>\n",
       "      <th>label</th>\n",
       "      <th>vaseq</th>\n",
       "      <th>vbseq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XXX</td>\n",
       "      <td>XXX</td>\n",
       "      <td>KLGGALQAK</td>\n",
       "      <td>A*03:01</td>\n",
       "      <td>human_microglobulin</td>\n",
       "      <td>human</td>\n",
       "      <td>human</td>\n",
       "      <td>7</td>\n",
       "      <td>93</td>\n",
       "      <td>CAPSGGSYIPTF</td>\n",
       "      <td>CASRFEGSTGELFF</td>\n",
       "      <td>0</td>\n",
       "      <td>XXX</td>\n",
       "      <td>XXX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XXX</td>\n",
       "      <td>XXX</td>\n",
       "      <td>KLGGALQAK</td>\n",
       "      <td>A*03:01</td>\n",
       "      <td>human_microglobulin</td>\n",
       "      <td>human</td>\n",
       "      <td>human</td>\n",
       "      <td>7</td>\n",
       "      <td>93</td>\n",
       "      <td>CAYRRWGAQKLVFF</td>\n",
       "      <td>CASKTGTLRTGPYEQYFF</td>\n",
       "      <td>1</td>\n",
       "      <td>XXX</td>\n",
       "      <td>XXX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XXX</td>\n",
       "      <td>XXX</td>\n",
       "      <td>KLGGALQAK</td>\n",
       "      <td>A*03:01</td>\n",
       "      <td>human_microglobulin</td>\n",
       "      <td>human</td>\n",
       "      <td>human</td>\n",
       "      <td>7</td>\n",
       "      <td>93</td>\n",
       "      <td>CTGNTPLVF</td>\n",
       "      <td>CAWGLGTGAQPQHF</td>\n",
       "      <td>0</td>\n",
       "      <td>XXX</td>\n",
       "      <td>XXX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XXX</td>\n",
       "      <td>XXX</td>\n",
       "      <td>KLGGALQAK</td>\n",
       "      <td>A*03:01</td>\n",
       "      <td>human_microglobulin</td>\n",
       "      <td>human</td>\n",
       "      <td>human</td>\n",
       "      <td>7</td>\n",
       "      <td>93</td>\n",
       "      <td>CALSEGGNQGGKLIF</td>\n",
       "      <td>CASSSDQKAGTFYEQFF</td>\n",
       "      <td>0</td>\n",
       "      <td>XXX</td>\n",
       "      <td>XXX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XXX</td>\n",
       "      <td>XXX</td>\n",
       "      <td>KLGGALQAK</td>\n",
       "      <td>A*03:01</td>\n",
       "      <td>human_microglobulin</td>\n",
       "      <td>human</td>\n",
       "      <td>human</td>\n",
       "      <td>7</td>\n",
       "      <td>93</td>\n",
       "      <td>CAVGHNNARLMF</td>\n",
       "      <td>CASSIQTGSLGGYTF</td>\n",
       "      <td>0</td>\n",
       "      <td>XXX</td>\n",
       "      <td>XXX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XXX</td>\n",
       "      <td>XXX</td>\n",
       "      <td>KLGGALQAK</td>\n",
       "      <td>A*03:01</td>\n",
       "      <td>human_microglobulin</td>\n",
       "      <td>human</td>\n",
       "      <td>human</td>\n",
       "      <td>7</td>\n",
       "      <td>93</td>\n",
       "      <td>CAVNKRDSSYKLIF</td>\n",
       "      <td>CASSLKASGNTGELFF</td>\n",
       "      <td>0</td>\n",
       "      <td>XXX</td>\n",
       "      <td>XXX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    vb   va    peptide     mhca                 mhcb pMHC_SPECIES TCR_SPECIES  \\\n",
       "0  XXX  XXX  KLGGALQAK  A*03:01  human_microglobulin        human       human   \n",
       "1  XXX  XXX  KLGGALQAK  A*03:01  human_microglobulin        human       human   \n",
       "2  XXX  XXX  KLGGALQAK  A*03:01  human_microglobulin        human       human   \n",
       "3  XXX  XXX  KLGGALQAK  A*03:01  human_microglobulin        human       human   \n",
       "4  XXX  XXX  KLGGALQAK  A*03:01  human_microglobulin        human       human   \n",
       "5  XXX  XXX  KLGGALQAK  A*03:01  human_microglobulin        human       human   \n",
       "\n",
       "   class  randn            cdr3a               cdr3b  label vaseq vbseq  \n",
       "0      7     93     CAPSGGSYIPTF      CASRFEGSTGELFF      0   XXX   XXX  \n",
       "1      7     93   CAYRRWGAQKLVFF  CASKTGTLRTGPYEQYFF      1   XXX   XXX  \n",
       "2      7     93        CTGNTPLVF      CAWGLGTGAQPQHF      0   XXX   XXX  \n",
       "3      7     93  CALSEGGNQGGKLIF   CASSSDQKAGTFYEQFF      0   XXX   XXX  \n",
       "4      7     93     CAVGHNNARLMF     CASSIQTGSLGGYTF      0   XXX   XXX  \n",
       "5      7     93   CAVNKRDSSYKLIF    CASSLKASGNTGELFF      0   XXX   XXX  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataset[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: /project/DPDS/Wang_lab/shared/pMTnet_v2/data/vcdr3pmhc/pos1negk50/pairing_training_Dec19_100_5.txt\n",
      "Number of rows in raw dataset: 662988\n",
      "Number of rows in this dataset after dropping NA: 662988\n",
      "540 MHCs without ESM embedding are dropped:\n",
      "['A*08:01' 'H-2-IAg7_alpha' 'A*02:15']\n",
      "['H-2-IAg7_beta']\n",
      "Number of rows in processed dataset: 662448\n"
     ]
    }
   ],
   "source": [
    "training_1batch = preprocess(\"/project/DPDS/Wang_lab/shared/pMTnet_v2/data/vcdr3pmhc/pos1negk50/pairing_training_Dec19_100_5.txt\", mhc_dic, \"mhca\", \"mhcb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAIR_PER_EPOCH = len(training_1batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: /project/DPDS/Wang_lab/shared/pMTnet_v2/data/vcdr3pmhc/pos1negk50/pairing_validation_Dec19_100_5.txt\n",
      "Number of rows in raw dataset: 5268\n",
      "Number of rows in this dataset after dropping NA: 5268\n",
      "Number of rows in processed dataset: 5268\n"
     ]
    }
   ],
   "source": [
    "validation_dataset=preprocess(\"/project/DPDS/Wang_lab/shared/pMTnet_v2/data/vcdr3pmhc/pos1negk50/pairing_validation_Dec19_100_5.txt\", mhc_dic, \"mhca\", \"mhcb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vb</th>\n",
       "      <th>va</th>\n",
       "      <th>data_file</th>\n",
       "      <th>peptide</th>\n",
       "      <th>mhca</th>\n",
       "      <th>mhcb</th>\n",
       "      <th>pMHC_SPECIES</th>\n",
       "      <th>TCR_SPECIES</th>\n",
       "      <th>valrandn</th>\n",
       "      <th>cdr3a</th>\n",
       "      <th>cdr3b</th>\n",
       "      <th>label</th>\n",
       "      <th>vaseq</th>\n",
       "      <th>vbseq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRBV11-3*01</td>\n",
       "      <td>TRAV12-2*01</td>\n",
       "      <td>Yu</td>\n",
       "      <td>KAFSPEVIPMF</td>\n",
       "      <td>B*57:01</td>\n",
       "      <td>human_microglobulin</td>\n",
       "      <td>human</td>\n",
       "      <td>human</td>\n",
       "      <td>72</td>\n",
       "      <td>CAVKLRPGNTPLVF</td>\n",
       "      <td>CASSPTRVSSYNEQFF</td>\n",
       "      <td>0</td>\n",
       "      <td>QKEVEQNSGPLSVPEGAIASLNCTYSDRGSQSFFWYRQYSGKSPEL...</td>\n",
       "      <td>EAGVVQSPRYKIIEKKQPVAFWCNPISGHNTLYWYLQNLGQGPELL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRBV11-3*01</td>\n",
       "      <td>TRAV19*01</td>\n",
       "      <td>Yu</td>\n",
       "      <td>KAFSPEVIPMF</td>\n",
       "      <td>B*57:01</td>\n",
       "      <td>human_microglobulin</td>\n",
       "      <td>human</td>\n",
       "      <td>human</td>\n",
       "      <td>72</td>\n",
       "      <td>CALSEDILTGGGNKLTF</td>\n",
       "      <td>CASSPTGPRNYGYTF</td>\n",
       "      <td>0</td>\n",
       "      <td>AQKVTQAQTEISVVEKEDVTLDCVYETRDTTYYLFWYKQPPSGELV...</td>\n",
       "      <td>EAGVVQSPRYKIIEKKQPVAFWCNPISGHNTLYWYLQNLGQGPELL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRBV13*01</td>\n",
       "      <td>TRAV38-2/DV8*01</td>\n",
       "      <td>Yu</td>\n",
       "      <td>KAFSPEVIPMF</td>\n",
       "      <td>B*57:01</td>\n",
       "      <td>human_microglobulin</td>\n",
       "      <td>human</td>\n",
       "      <td>human</td>\n",
       "      <td>72</td>\n",
       "      <td>CVLCIYGNKLVF</td>\n",
       "      <td>CASSSGLAGTKTQYF</td>\n",
       "      <td>0</td>\n",
       "      <td>AQTVTQSQPEMSVQEAETVTLSCTYDTSESDYYLFWYKQPPSRQMI...</td>\n",
       "      <td>AAGVIQSPRHLIKEKRETATLKCYPIPRHDTVYWYQQGPGQDPQFL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRBV19*01</td>\n",
       "      <td>TRAV5*01</td>\n",
       "      <td>Yu</td>\n",
       "      <td>KAFSPEVIPMF</td>\n",
       "      <td>B*57:01</td>\n",
       "      <td>human_microglobulin</td>\n",
       "      <td>human</td>\n",
       "      <td>human</td>\n",
       "      <td>72</td>\n",
       "      <td>CAESGGYQKVTF</td>\n",
       "      <td>CATTGSYGYTF</td>\n",
       "      <td>1</td>\n",
       "      <td>GEDVEQSLFLSVREGDSSVINCTYTDSSSTYLYWYKQEPGAGLQLL...</td>\n",
       "      <td>DGGITQSPKYLFRKEGQNVTLSCEQNLNHDAMYWYRQDPGQGLRLI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRBV10-3*01</td>\n",
       "      <td>TRAV21*01</td>\n",
       "      <td>Yu</td>\n",
       "      <td>KAFSPEVIPMF</td>\n",
       "      <td>B*57:01</td>\n",
       "      <td>human_microglobulin</td>\n",
       "      <td>human</td>\n",
       "      <td>human</td>\n",
       "      <td>72</td>\n",
       "      <td>CAVRPDSGNTGKLIF</td>\n",
       "      <td>CAIRQAGTEAFF</td>\n",
       "      <td>0</td>\n",
       "      <td>KQEVTQIPAALSVPEGENLVLNCSFTDSAIYNLQWFRQDPGKGLTS...</td>\n",
       "      <td>DAGITQSPRHKVTETGTPVTLRCHQTENHRYMYWYRQDPGHGLRLI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TRBV11-3*01</td>\n",
       "      <td>TRAV39*01</td>\n",
       "      <td>Yu</td>\n",
       "      <td>KAFSPEVIPMF</td>\n",
       "      <td>B*57:01</td>\n",
       "      <td>human_microglobulin</td>\n",
       "      <td>human</td>\n",
       "      <td>human</td>\n",
       "      <td>72</td>\n",
       "      <td>CAVATNAGNMLTF</td>\n",
       "      <td>CASSRGFGREHTEAFF</td>\n",
       "      <td>0</td>\n",
       "      <td>ELKVEQNPLFLSMQEGKNYTIYCNYSTTSDRLYWYRQDPGKSLESL...</td>\n",
       "      <td>EAGVVQSPRYKIIEKKQPVAFWCNPISGHNTLYWYLQNLGQGPELL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TRBV14*01</td>\n",
       "      <td>TRAV13-1*01</td>\n",
       "      <td>Schinkelshoek</td>\n",
       "      <td>ERNAGSGIIISDT</td>\n",
       "      <td>DQA1*01:02</td>\n",
       "      <td>DQB1*06:02</td>\n",
       "      <td>human</td>\n",
       "      <td>human</td>\n",
       "      <td>211</td>\n",
       "      <td>CAASARGGADGLTF</td>\n",
       "      <td>CASSLPGTSTNEKLFF</td>\n",
       "      <td>0</td>\n",
       "      <td>GENVEQHPSTLSVQEGDSAVIKCTYSDSASNYFPWYKQELGKGPQL...</td>\n",
       "      <td>EAGVTQFPSHSVIEKGQTVTLRCDPISGHDNLYWYRRVMGKEIKFL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TRBV19*01</td>\n",
       "      <td>TRAV29/DV5*01</td>\n",
       "      <td>Schinkelshoek</td>\n",
       "      <td>ERNAGSGIIISDT</td>\n",
       "      <td>DQA1*01:02</td>\n",
       "      <td>DQB1*06:02</td>\n",
       "      <td>human</td>\n",
       "      <td>human</td>\n",
       "      <td>211</td>\n",
       "      <td>CAASSDTGANSKLTF</td>\n",
       "      <td>CASSMGQANTEAFF</td>\n",
       "      <td>0</td>\n",
       "      <td>DQQVKQNSPSLSVQEGRISILNCDYTNSMFDYFLWYKKYPAEGPTF...</td>\n",
       "      <td>DGGITQSPKYLFRKEGQNVTLSCEQNLNHDAMYWYRQDPGQGLRLI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TRBV11-3*01</td>\n",
       "      <td>TRAV12-2*01</td>\n",
       "      <td>Schinkelshoek</td>\n",
       "      <td>ERNAGSGIIISDT</td>\n",
       "      <td>DQA1*01:02</td>\n",
       "      <td>DQB1*06:02</td>\n",
       "      <td>human</td>\n",
       "      <td>human</td>\n",
       "      <td>211</td>\n",
       "      <td>CAVKIGGFQKLVF</td>\n",
       "      <td>CASSLVDRGEQFF</td>\n",
       "      <td>0</td>\n",
       "      <td>QKEVEQNSGPLSVPEGAIASLNCTYSDRGSQSFFWYRQYSGKSPEL...</td>\n",
       "      <td>EAGVVQSPRYKIIEKKQPVAFWCNPISGHNTLYWYLQNLGQGPELL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TRBV4-3*01</td>\n",
       "      <td>TRAV17*01</td>\n",
       "      <td>Schinkelshoek</td>\n",
       "      <td>ERNAGSGIIISDT</td>\n",
       "      <td>DQA1*01:02</td>\n",
       "      <td>DQB1*06:02</td>\n",
       "      <td>human</td>\n",
       "      <td>human</td>\n",
       "      <td>211</td>\n",
       "      <td>CATASYNTDKLIF</td>\n",
       "      <td>CASSRGTAATNEKLF</td>\n",
       "      <td>1</td>\n",
       "      <td>SQQGEEDPQALSIQEGENATMNCSYKTSINNLQWYRQNSGRGLVHL...</td>\n",
       "      <td>ETGVTQTPRHLVMGMTNKKSLKCEQHLGHNAMYWYKQSAKKPLELM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TRBV11-2*02</td>\n",
       "      <td>TRAV38-2/DV8*01</td>\n",
       "      <td>Schinkelshoek</td>\n",
       "      <td>ERNAGSGIIISDT</td>\n",
       "      <td>DQA1*01:02</td>\n",
       "      <td>DQB1*06:02</td>\n",
       "      <td>human</td>\n",
       "      <td>human</td>\n",
       "      <td>211</td>\n",
       "      <td>CAYRSARSNSGYALNF</td>\n",
       "      <td>CASSLRPKLHYGYTF</td>\n",
       "      <td>0</td>\n",
       "      <td>AQTVTQSQPEMSVQEAETVTLSCTYDTSESDYYLFWYKQPPSRQMI...</td>\n",
       "      <td>EAGVAQSPRYKIIEKRQSVAFWCNPISGHATLYWYQQILGQGPKLL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TRBV11-3*01</td>\n",
       "      <td>TRAV21*01</td>\n",
       "      <td>Schinkelshoek</td>\n",
       "      <td>ERNAGSGIIISDT</td>\n",
       "      <td>DQA1*01:02</td>\n",
       "      <td>DQB1*06:02</td>\n",
       "      <td>human</td>\n",
       "      <td>human</td>\n",
       "      <td>211</td>\n",
       "      <td>CAVRGDNDMRF</td>\n",
       "      <td>CASSAQGRRFQPQHF</td>\n",
       "      <td>0</td>\n",
       "      <td>KQEVTQIPAALSVPEGENLVLNCSFTDSAIYNLQWFRQDPGKGLTS...</td>\n",
       "      <td>EAGVVQSPRYKIIEKKQPVAFWCNPISGHNTLYWYLQNLGQGPELL...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             vb               va      data_file        peptide        mhca  \\\n",
       "0   TRBV11-3*01      TRAV12-2*01             Yu    KAFSPEVIPMF     B*57:01   \n",
       "1   TRBV11-3*01        TRAV19*01             Yu    KAFSPEVIPMF     B*57:01   \n",
       "2     TRBV13*01  TRAV38-2/DV8*01             Yu    KAFSPEVIPMF     B*57:01   \n",
       "3     TRBV19*01         TRAV5*01             Yu    KAFSPEVIPMF     B*57:01   \n",
       "4   TRBV10-3*01        TRAV21*01             Yu    KAFSPEVIPMF     B*57:01   \n",
       "5   TRBV11-3*01        TRAV39*01             Yu    KAFSPEVIPMF     B*57:01   \n",
       "6     TRBV14*01      TRAV13-1*01  Schinkelshoek  ERNAGSGIIISDT  DQA1*01:02   \n",
       "7     TRBV19*01    TRAV29/DV5*01  Schinkelshoek  ERNAGSGIIISDT  DQA1*01:02   \n",
       "8   TRBV11-3*01      TRAV12-2*01  Schinkelshoek  ERNAGSGIIISDT  DQA1*01:02   \n",
       "9    TRBV4-3*01        TRAV17*01  Schinkelshoek  ERNAGSGIIISDT  DQA1*01:02   \n",
       "10  TRBV11-2*02  TRAV38-2/DV8*01  Schinkelshoek  ERNAGSGIIISDT  DQA1*01:02   \n",
       "11  TRBV11-3*01        TRAV21*01  Schinkelshoek  ERNAGSGIIISDT  DQA1*01:02   \n",
       "\n",
       "                   mhcb pMHC_SPECIES TCR_SPECIES  valrandn              cdr3a  \\\n",
       "0   human_microglobulin        human       human        72     CAVKLRPGNTPLVF   \n",
       "1   human_microglobulin        human       human        72  CALSEDILTGGGNKLTF   \n",
       "2   human_microglobulin        human       human        72       CVLCIYGNKLVF   \n",
       "3   human_microglobulin        human       human        72       CAESGGYQKVTF   \n",
       "4   human_microglobulin        human       human        72    CAVRPDSGNTGKLIF   \n",
       "5   human_microglobulin        human       human        72      CAVATNAGNMLTF   \n",
       "6            DQB1*06:02        human       human       211     CAASARGGADGLTF   \n",
       "7            DQB1*06:02        human       human       211    CAASSDTGANSKLTF   \n",
       "8            DQB1*06:02        human       human       211      CAVKIGGFQKLVF   \n",
       "9            DQB1*06:02        human       human       211      CATASYNTDKLIF   \n",
       "10           DQB1*06:02        human       human       211   CAYRSARSNSGYALNF   \n",
       "11           DQB1*06:02        human       human       211        CAVRGDNDMRF   \n",
       "\n",
       "               cdr3b  label  \\\n",
       "0   CASSPTRVSSYNEQFF      0   \n",
       "1    CASSPTGPRNYGYTF      0   \n",
       "2    CASSSGLAGTKTQYF      0   \n",
       "3        CATTGSYGYTF      1   \n",
       "4       CAIRQAGTEAFF      0   \n",
       "5   CASSRGFGREHTEAFF      0   \n",
       "6   CASSLPGTSTNEKLFF      0   \n",
       "7     CASSMGQANTEAFF      0   \n",
       "8      CASSLVDRGEQFF      0   \n",
       "9    CASSRGTAATNEKLF      1   \n",
       "10   CASSLRPKLHYGYTF      0   \n",
       "11   CASSAQGRRFQPQHF      0   \n",
       "\n",
       "                                                vaseq  \\\n",
       "0   QKEVEQNSGPLSVPEGAIASLNCTYSDRGSQSFFWYRQYSGKSPEL...   \n",
       "1   AQKVTQAQTEISVVEKEDVTLDCVYETRDTTYYLFWYKQPPSGELV...   \n",
       "2   AQTVTQSQPEMSVQEAETVTLSCTYDTSESDYYLFWYKQPPSRQMI...   \n",
       "3   GEDVEQSLFLSVREGDSSVINCTYTDSSSTYLYWYKQEPGAGLQLL...   \n",
       "4   KQEVTQIPAALSVPEGENLVLNCSFTDSAIYNLQWFRQDPGKGLTS...   \n",
       "5   ELKVEQNPLFLSMQEGKNYTIYCNYSTTSDRLYWYRQDPGKSLESL...   \n",
       "6   GENVEQHPSTLSVQEGDSAVIKCTYSDSASNYFPWYKQELGKGPQL...   \n",
       "7   DQQVKQNSPSLSVQEGRISILNCDYTNSMFDYFLWYKKYPAEGPTF...   \n",
       "8   QKEVEQNSGPLSVPEGAIASLNCTYSDRGSQSFFWYRQYSGKSPEL...   \n",
       "9   SQQGEEDPQALSIQEGENATMNCSYKTSINNLQWYRQNSGRGLVHL...   \n",
       "10  AQTVTQSQPEMSVQEAETVTLSCTYDTSESDYYLFWYKQPPSRQMI...   \n",
       "11  KQEVTQIPAALSVPEGENLVLNCSFTDSAIYNLQWFRQDPGKGLTS...   \n",
       "\n",
       "                                                vbseq  \n",
       "0   EAGVVQSPRYKIIEKKQPVAFWCNPISGHNTLYWYLQNLGQGPELL...  \n",
       "1   EAGVVQSPRYKIIEKKQPVAFWCNPISGHNTLYWYLQNLGQGPELL...  \n",
       "2   AAGVIQSPRHLIKEKRETATLKCYPIPRHDTVYWYQQGPGQDPQFL...  \n",
       "3   DGGITQSPKYLFRKEGQNVTLSCEQNLNHDAMYWYRQDPGQGLRLI...  \n",
       "4   DAGITQSPRHKVTETGTPVTLRCHQTENHRYMYWYRQDPGHGLRLI...  \n",
       "5   EAGVVQSPRYKIIEKKQPVAFWCNPISGHNTLYWYLQNLGQGPELL...  \n",
       "6   EAGVTQFPSHSVIEKGQTVTLRCDPISGHDNLYWYRRVMGKEIKFL...  \n",
       "7   DGGITQSPKYLFRKEGQNVTLSCEQNLNHDAMYWYRQDPGQGLRLI...  \n",
       "8   EAGVVQSPRYKIIEKKQPVAFWCNPISGHNTLYWYLQNLGQGPELL...  \n",
       "9   ETGVTQTPRHLVMGMTNKKSLKCEQHLGHNAMYWYKQSAKKPLELM...  \n",
       "10  EAGVAQSPRYKIIEKRQSVAFWCNPISGHATLYWYQQILGQGPKLL...  \n",
       "11  EAGVVQSPRYKIIEKKQPVAFWCNPISGHNTLYWYLQNLGQGPELL...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_dataset[0:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human c1 validation pairs: 2544\n",
      "human c2 validation pairs: 2304\n",
      "mouse c1 validation pairs: 270\n",
      "mouse c2 validation pairs: 150\n"
     ]
    }
   ],
   "source": [
    "validation_hc1 = validation_dataset[(validation_dataset['pMHC_SPECIES']==\"human\") & (validation_dataset['mhcb']==\"human_microglobulin\")]\n",
    "validation_hc2 = validation_dataset[(validation_dataset['pMHC_SPECIES']==\"human\") & (validation_dataset['mhcb']!=\"human_microglobulin\")]\n",
    "validation_mc1 = validation_dataset[(validation_dataset['pMHC_SPECIES']==\"mouse\") & (validation_dataset['mhcb']==\"mouse_microglobulin\")]\n",
    "validation_mc2 = validation_dataset[(validation_dataset['pMHC_SPECIES']==\"mouse\") & (validation_dataset['mhcb']!=\"mouse_microglobulin\")]\n",
    "print(\"human c1 validation pairs: \"+str(len(validation_hc1)))\n",
    "print(\"human c2 validation pairs: \"+str(len(validation_hc2)))\n",
    "print(\"mouse c1 validation pairs: \"+str(len(validation_mc1)))\n",
    "print(\"mouse c2 validation pairs: \"+str(len(validation_mc2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "used device is:cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:\"+str(CUDA) if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"used device is:\" + str(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLmodel, pMHCmodel, vGdVAEamodel, vGdVAEbmodel, cdr3VAEamodel, cdr3VAEbmodel = set_model(device)\n",
    "#CLmodel2, pMHCmodel2, vGdVAEamodel2, vGdVAEbmodel2, cdr3VAEamodel2, cdr3VAEbmodel2 = set_model(device)\n",
    "#CLmodel3, pMHCmodel3, vGdVAEamodel3, vGdVAEbmodel3, cdr3VAEamodel3, cdr3VAEbmodel3 = set_model(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "AdamOptimizer = torch.optim.Adam(CLmodel.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, metric of validation dataset is: 1.8588364933509218, time elapsed: 28.795634269714355\n"
     ]
    }
   ],
   "source": [
    "time_tmp1 = time.time()\n",
    "val_metric = val(validation_dataset, CLmodel, pMHCmodel, vGdVAEamodel, vGdVAEbmodel, cdr3VAEamodel, cdr3VAEbmodel, LossFunction2, device)\n",
    "print(\"Before training, metric of validation dataset is: \" + str(val_metric) + \", time elapsed: \" + str(time.time()-time_tmp1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, metric of validation dataset is: 1.8525143582076853, time elapsed: 24.48460602760315\n"
     ]
    }
   ],
   "source": [
    "time_tmp1 = time.time()\n",
    "val_metric = val(validation_dataset, CLmodel, pMHCmodel, vGdVAEamodel, vGdVAEbmodel, cdr3VAEamodel, cdr3VAEbmodel, LossFunction2, device)\n",
    "print(\"Before training, metric of validation dataset is: \" + str(val_metric) + \", time elapsed: \" + str(time.time()-time_tmp1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, metric of validation dataset is: h c1:1.90790, h c2:1.78276, m c1:2.02987, m c2:1.73645\n"
     ]
    }
   ],
   "source": [
    "val_hc1_metric = val(validation_hc1, CLmodel, pMHCmodel, vGdVAEamodel, vGdVAEbmodel, cdr3VAEamodel, cdr3VAEbmodel, LossFunction2, device)\n",
    "val_hc2_metric = val(validation_hc2, CLmodel, pMHCmodel, vGdVAEamodel, vGdVAEbmodel, cdr3VAEamodel, cdr3VAEbmodel, LossFunction2, device)\n",
    "val_mc1_metric = val(validation_mc1, CLmodel, pMHCmodel, vGdVAEamodel, vGdVAEbmodel, cdr3VAEamodel, cdr3VAEbmodel, LossFunction2, device)\n",
    "val_mc2_metric = val(validation_mc2, CLmodel, pMHCmodel, vGdVAEamodel, vGdVAEbmodel, cdr3VAEamodel, cdr3VAEbmodel, LossFunction2, device)\n",
    "print(\"Before training, metric of validation dataset is: h c1:{:.5f}, h c2:{:.5f}, m c1:{:.5f}, m c2:{:.5f}\".format(val_hc1_metric,val_hc2_metric,val_mc1_metric,val_mc2_metric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, metric of validation dataset is: h c1:1.90407, h c2:1.78555, m c1:2.00835, m c2:1.77115\n"
     ]
    }
   ],
   "source": [
    "val_hc1_metric = val(validation_hc1, CLmodel, pMHCmodel, vGdVAEamodel, vGdVAEbmodel, cdr3VAEamodel, cdr3VAEbmodel, LossFunction2, device)\n",
    "val_hc2_metric = val(validation_hc2, CLmodel, pMHCmodel, vGdVAEamodel, vGdVAEbmodel, cdr3VAEamodel, cdr3VAEbmodel, LossFunction2, device)\n",
    "val_mc1_metric = val(validation_mc1, CLmodel, pMHCmodel, vGdVAEamodel, vGdVAEbmodel, cdr3VAEamodel, cdr3VAEbmodel, LossFunction2, device)\n",
    "val_mc2_metric = val(validation_mc2, CLmodel, pMHCmodel, vGdVAEamodel, vGdVAEbmodel, cdr3VAEamodel, cdr3VAEbmodel, LossFunction2, device)\n",
    "print(\"Before training, metric of validation dataset is: h c1:{:.5f}, h c2:{:.5f}, m c1:{:.5f}, m c2:{:.5f}\".format(val_hc1_metric,val_hc2_metric,val_mc1_metric,val_mc2_metric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for epoch in range(0, EPOCH):\n",
    "        epoch_start_time = time.time()\n",
    "        \n",
    "        train_loss = train(training_dataset[PAIR_PER_EPOCH*epoch:PAIR_PER_EPOCH*(epoch+1)], CLmodel, pMHCmodel, vGdVAEamodel, vGdVAEbmodel, cdr3VAEamodel, cdr3VAEbmodel, LossFunction2, AdamOptimizer, device)\n",
    "        val_metric = val(validation_dataset, CLmodel, pMHCmodel, vGdVAEamodel, vGdVAEbmodel, cdr3VAEamodel, cdr3VAEbmodel, LossFunction2, device)\n",
    "        val_hc1_metric = val(validation_hc1, CLmodel, pMHCmodel, vGdVAEamodel, vGdVAEbmodel, cdr3VAEamodel, cdr3VAEbmodel, LossFunction2, device)\n",
    "        val_hc2_metric = val(validation_hc2, CLmodel, pMHCmodel, vGdVAEamodel, vGdVAEbmodel, cdr3VAEamodel, cdr3VAEbmodel, LossFunction2, device)\n",
    "        val_mc1_metric = val(validation_mc1, CLmodel, pMHCmodel, vGdVAEamodel, vGdVAEbmodel, cdr3VAEamodel, cdr3VAEbmodel, LossFunction2, device)\n",
    "        val_mc2_metric = val(validation_mc2, CLmodel, pMHCmodel, vGdVAEamodel, vGdVAEbmodel, cdr3VAEamodel, cdr3VAEbmodel, LossFunction2, device)\n",
    "        \n",
    "        print(\"Epoch:{}, Train Loss:{:.5f}, Validation Loss:{:.5f}, human c1:{:.5f}, human c2:{:.5f}, mouse c1:{:.5f}, mouse c2:{:.5f}, Time:{:.5f}\".format(epoch+1,train_loss,val_metric,val_hc1_metric,val_hc2_metric,val_mc1_metric,val_mc2_metric,time.time()-epoch_start_time))\n",
    "            \n",
    "except KeyboardInterrupt:\n",
    "    print('-' * 89) \n",
    "    print('Exiting from training early')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pMTnet_Omni",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Nov 24 2022, 08:09:04) [Clang 14.0.6 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "8ee2ad263e01ee75f2f0374f9835e7090ddce8a9d62f1c225e74aacfeecd9567"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
